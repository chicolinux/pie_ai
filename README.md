# Pie & AI
Pie &amp; AI Meetups are designed to cover topics that you wouldn't see in your regular AI/ML/DL classes. These meetups are meant to expand your knowledge about different aspects of AI &amp; ML. Specifically, we are more focused on the intersection of AI/ML and Security and Safety.  Common topics:  alignment, control, red teaming, jailbreaking,

## Sep 19th, 2025 Meeting
- Measuring Thinking Efficiency in Reasoning Models: The Missing Benchmark. Large Reasoning Models (LRMs) employ a novel paradigm known as test-time scaling, leveraging reinforcement learning to teach the models to generate extended chains of thought (CoT) during reasoning tasks. This enhances their problem-solving capabilities beyond what their base models could achieve independently. While cost and efficiency trade-off curves ("the Pareto frontier") typically focus on model intelligence versus cost per million completion tokens, token efficiency — the number of tokens used for reasoning relative to the solution — is a critical factor that is recently receiving more attention. Anecdotal evidence suggests open weight models produce significantly more tokens for similar tasks than closed weight models.
- Agent Red-Teaming Benchmark. Researchers curated a collection of jailbreaks that can reliably cause frontier LLMs to pursue a wide array of misaligned goals. Researchers from Gray Swan AI and the UK AI Security Institute created a benchmark, Agent Red-Teaming (ART), with advanced jailbreaks that generalize broadly across frontier model agents.
